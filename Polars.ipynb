{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d069b82a-adc0-4d89-8760-6c950a2eafbd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"YourAppName\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6579cb09-7ecd-4a11-b91b-4705d9bf9c87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.databricks.io.cache.enabled is false\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.databricks.io.cache.enabled\", \"false\")\n",
    "print(\"spark.databricks.io.cache.enabled is %s\" % spark.conf.get(\"spark.databricks.io.cache.enabled\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6a2f72d-5777-4360-962c-b34d88519a90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting polars\n  Using cached polars-0.20.31-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.8 MB)\nInstalling collected packages: polars\nSuccessfully installed polars-0.20.31\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "599269d2-2a93-4ffc-9200-d99bb3a6869d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 1.4.2\nnumpy version: 1.21.5\npolars version: 0.20.31\npyarrow version: 7.0.0\npyspark version: 3.3.2.dev0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "#import databricks.koalas as ks\n",
    "# import dask.dataframe as dd\n",
    "# from dask.distributed import Client, LocalCluster\n",
    "\n",
    "print('pandas version: %s' % pd.__version__)\n",
    "\n",
    "print('numpy version: %s' % np.__version__)\n",
    "\n",
    "print('polars version: %s' % pl.__version__)\n",
    "\n",
    "#print('koalas version: %s' % ks.__version__)\n",
    "\n",
    "# import dask\n",
    "# print('dask version: %s' % dask.__version__)\n",
    "\n",
    "import pyarrow\n",
    "print('pyarrow version: %s' % pyarrow.__version__)\n",
    "\n",
    "import pyspark\n",
    "print('pyspark version: %s' % pyspark.__version__)\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "def benchmark(f, df, benchmarks, name, **kwargs):\n",
    "    \"\"\"Benchmark the given function against the given DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f: function to benchmark\n",
    "    df: data frame\n",
    "    benchmarks: container for benchmark results\n",
    "    name: task name\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Duration (in seconds) of the given operation\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    ret = f(df, **kwargs)\n",
    "    benchmarks['duration'].append(time.time() - start_time)\n",
    "    benchmarks['task'].append(name)\n",
    "    print(f\"{name} took: {benchmarks['duration'][-1]} seconds\")\n",
    "    return benchmarks['duration'][-1]\n",
    "\n",
    "def get_results(benchmarks):\n",
    "    \"\"\"Return a pandas DataFrame containing benchmark results.\"\"\"\n",
    "    return pd.DataFrame.from_dict(benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a8f66a0-28ad-4519-84c0-194646724474",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filenames = [f\"/FileStore/tables/yellow_tripdata_2023_0{i}.parquet\" for i in range(1, 6)]\n",
    "\n",
    "dfs = []\n",
    "for filename in filenames:\n",
    "    # df = pd.read_parquet(filename)\n",
    "    df = spark.read.format('parquet').options(header='true').load(filename).toPandas()\n",
    "\n",
    "    if 'airport_fee' in df.columns:\n",
    "        df.rename(columns={'airport_fee': 'Airport_fee'}, inplace=True)\n",
    "    # df_pl = pl.from_pandas(df, npartitions=3)\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "pandas_data = pd.concat(dfs, ignore_index=True)\n",
    "polars_data = pl.from_pandas(pandas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aa7985d-a041-4686-b114-948147c75e87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[3]: 16186386"
     ]
    }
   ],
   "source": [
    "len(polars_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ec1fe2e-2519-4671-95e4-079c9901f593",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# polars_data = pl.from_pandas(pandas_data)\n",
    "polars_benchmarks = {\n",
    "    'duration': [],  # in seconds\n",
    "    'task': [],\n",
    "}\n",
    "# polars_data.1head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca3e572c-5d1d-4815-be1f-cb1c914bda73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<command-1433832980640705>:53: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n  result = df.groupby(\"passenger_count\").agg([\n"
     ]
    }
   ],
   "source": [
    "def read_file_parquet():\n",
    "    return pl.read_parquet(\"/FileStore/tables/yellow_tripdata_2023_01.parquet\")\n",
    "\n",
    "def count(df):\n",
    "    return df.height\n",
    "\n",
    "def count_index_length(df):\n",
    "    return df.shape[0]\n",
    "\n",
    "def mean(df):\n",
    "    return df.select(pl.col(\"fare_amount\").mean()).to_numpy().item()\n",
    "\n",
    "def standard_deviation(df):\n",
    "    return df.select(pl.col(\"fare_amount\").std()).to_numpy().item()\n",
    "\n",
    "def mean_of_sum(df):\n",
    "    return df.with_columns((pl.col(\"fare_amount\") + pl.col(\"tip_amount\")).alias(\"sum\")).select(pl.col(\"sum\").mean()).to_numpy().item()\n",
    "\n",
    "def sum_columns(df):\n",
    "    return df.with_columns((pl.col(\"fare_amount\") + pl.col(\"tip_amount\")).alias(\"sum\"))[\"sum\"]\n",
    "\n",
    "def mean_of_product(df):\n",
    "    return df.with_columns((pl.col(\"fare_amount\") * pl.col(\"tip_amount\")).alias(\"product\")).select(pl.col(\"product\").mean()).to_numpy().item()\n",
    "\n",
    "def product_columns(df):\n",
    "    return df.with_columns((pl.col(\"fare_amount\") * pl.col(\"tip_amount\")).alias(\"product\"))[\"product\"]\n",
    "\n",
    "def value_counts(df):\n",
    "    # return df.select(pl.col(\"fare_amount\")).value_counts()\n",
    "    return df.groupby(\"fare_amount\").agg(pl.col(\"fare_amount\").count().alias(\"counts\")).sort(\"counts\")\n",
    "\n",
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    theta_1 = df[\"start_lon\"]\n",
    "    phi_1 = df[\"start_lat\"]\n",
    "    theta_2 = df[\"end_lon\"]\n",
    "    phi_2 = df[\"end_lat\"]\n",
    "    temp = (np.sin((theta_2 - theta_1) / 2 * np.pi / 180)**2 +\n",
    "            np.cos(theta_1 * np.pi / 180) * np.cos(theta_2 * np.pi / 180) * np.sin((phi_2 - phi_1) / 2 * np.pi / 180)**2)\n",
    "    ret = 2 * np.arctan2(np.sqrt(temp), np.sqrt(1 - temp))\n",
    "    return pl.Series(ret).mean()\n",
    "\n",
    "def complicated_arithmetic_operation(df):\n",
    "    theta_1 = df[\"start_lon\"]\n",
    "    phi_1 = df[\"start_lat\"]\n",
    "    theta_2 = df[\"end_lon\"]\n",
    "    phi_2 = df[\"end_lat\"]\n",
    "    temp = (np.sin((theta_2 - theta_1) / 2 * np.pi / 180)**2 +\n",
    "            np.cos(theta_1 * np.pi / 180) * np.cos(theta_2 * np.pi / 180) * np.sin((phi_2 - phi_1) / 2 * np.pi / 180)**2)\n",
    "    ret = 2 * np.arctan2(np.sqrt(temp), np.sqrt(1 - temp))\n",
    "    return ret\n",
    "\n",
    "def groupby_statistics(df):\n",
    "    result = df.groupby(\"passenger_count\").agg([\n",
    "        pl.col(\"fare_amount\").mean().alias(\"fare_amount_mean\"),\n",
    "        pl.col(\"fare_amount\").std().alias(\"fare_amount_std\"),\n",
    "        pl.col(\"tip_amount\").mean().alias(\"tip_amount_mean\"),\n",
    "        pl.col(\"tip_amount\").std().alias(\"tip_amount_std\")\n",
    "    ])\n",
    "    return result\n",
    "\n",
    "# other = groupby_statistics(polars_data)\n",
    "# other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "\n",
    "other = groupby_statistics(polars_data)\n",
    "# other.columns = [\"_\".join(col) for col in other.columns]\n",
    "# other.columns = new_column_names\n",
    "# other.columns = [e[0]+'_' + e[1] for e in other.columns]\n",
    "\n",
    "def join_count(df, other):\n",
    "    # return df.join(other, left_on=\"index\", right_on=\"index\", how=\"inner\").shape[0]\n",
    "    return df.join(other, on=\"passenger_count\", how=\"inner\").shape[0]\n",
    "\n",
    "def join_data(df, other):\n",
    "    # return df.join(other, left_on=\"index\", right_on=\"index\", how=\"inner\")\n",
    "    return df.join(other, on=\"passenger_count\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "670bbe61-d0b1-4cc6-9c3e-560f24e29f17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mThe Python process exited with exit code 137 (SIGKILL: Killed). This may have been caused by an OOM error. Check your command's memory usage.\u001B[0m\n",
       "\u001B[0;31m\u001B[0m\n",
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mThe last 10 KB of the process's stderr and stdout can be found below. See driver logs for full logs.\u001B[0m\n",
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mLast messages on stderr:\u001B[0m\n",
       "\u001B[0;31mSun Jun  2 17:05:58 2024 Connection to spark from PID  5662\u001B[0m\n",
       "\u001B[0;31mSun Jun  2 17:05:58 2024 Initialized gateway on port 39861\u001B[0m\n",
       "\u001B[0;31mSun Jun  2 17:05:58 2024 Connected to spark.\u001B[0m\n",
       "\u001B[0;31m<command-1433832980640705>:53: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\u001B[0m\n",
       "\u001B[0;31m  result = df.groupby(\"passenger_count\").agg([\u001B[0m\n",
       "\u001B[0;31m<command-1433832980640705>:30: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\u001B[0m\n",
       "\u001B[0;31m  return df.groupby(\"fare_amount\").agg(pl.col(\"fare_amount\").count().alias(\"counts\")).sort(\"counts\")\u001B[0m\n",
       "\u001B[0;31m<command-1433832980640705>:53: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\u001B[0m\n",
       "\u001B[0;31m  result = df.groupby(\"passenger_count\").agg([\u001B[0m\n",
       "\u001B[0;31m<command-1433832980640705>:30: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\u001B[0m\n",
       "\u001B[0;31m  return df.groupby(\"fare_amount\").agg(pl.col(\"fare_amount\").count().alias(\"counts\")).sort(\"counts\")\u001B[0m\n",
       "\u001B[0;31m<command-1433832980640705>:53: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\u001B[0m\n",
       "\u001B[0;31m  result = df.groupby(\"passenger_count\").agg([\u001B[0m\n",
       "\u001B[0;31m<command-1433832980640705>:30: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\u001B[0m\n",
       "\u001B[0;31m  return df.groupby(\"fare_amount\").agg(pl.col(\"fare_amount\").count().alias(\"counts\")).sort(\"counts\")\u001B[0m\n",
       "\u001B[0;31m<command-1433832980640705>:53: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\u001B[0m\n",
       "\u001B[0;31m  result = df.groupby(\"passenger_count\").agg([\u001B[0m\n",
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mLast messages on stdout:\u001B[0m\n",
       "\u001B[0;31mNOTE: When using the `ipython kernel` entry point, Ctrl-C will not work.\u001B[0m\n",
       "\u001B[0;31m\u001B[0m\n",
       "\u001B[0;31mTo exit, you will have to explicitly quit this process, by either sending\u001B[0m\n",
       "\u001B[0;31m\"quit\" from a client, or using Ctrl-\\ in UNIX-like environments.\u001B[0m\n",
       "\u001B[0;31m\u001B[0m\n",
       "\u001B[0;31mTo read more about this, see https://github.com/ipython/ipython/issues/2049\u001B[0m\n",
       "\u001B[0;31m\u001B[0m\n",
       "\u001B[0;31m\u001B[0m\n",
       "\u001B[0;31mTo connect another client to this kernel, use:\u001B[0m\n",
       "\u001B[0;31m    --existing /databricks/kernel-connections/94a690f7212ef9de48f914f409adb646fee4bec6693c856d278c40e6a4c27512.json\u001B[0m\n",
       "\u001B[0;31mpandas version: 1.4.2\u001B[0m\n",
       "\u001B[0;31mnumpy version: 1.21.5\u001B[0m\n",
       "\u001B[0;31mpolars version: 0.20.31\u001B[0m\n",
       "\u001B[0;31mpyarrow version: 7.0.0\u001B[0m\n",
       "\u001B[0;31mpyspark version: 3.3.2.dev0\u001B[0m\n",
       "\u001B[0;31mcount took: 0.0005140304565429688 seconds\u001B[0m\n",
       "\u001B[0;31mcount index length took: 1.1682510375976562e-05 seconds\u001B[0m\n",
       "\u001B[0;31mmean took: 0.03813910484313965 seconds\u001B[0m\n",
       "\u001B[0;31mstandard deviation took: 0.26393985748291016 seconds\u001B[0m\n",
       "\u001B[0;31mmean of columns addition took: 0.1642138957977295 seconds\u001B[0m\n",
       "\u001B[0;31maddition of columns took: 0.13327717781066895 seconds\u001B[0m\n",
       "\u001B[0;31mmean of columns multiplication took: 0.1623995304107666 seconds\u001B[0m\n",
       "\u001B[0;31mmultiplication of columns took: 0.13460636138916016 seconds\u001B[0m\n",
       "\u001B[0;31mvalue counts took: 0.5112097263336182 seconds\u001B[0m\n",
       "\u001B[0;31mgroupby statistics took: 0.7490234375 seconds\u001B[0m\n",
       "\u001B[0;31mjoin count took: 16.132195234298706 seconds\u001B[0m\n",
       "\u001B[0;31mjoin took: 5.184712171554565 seconds\u001B[0m\n",
       "\u001B[0;31mfiltered count took: 1.52587890625e-05 seconds\u001B[0m\n",
       "\u001B[0;31mfiltered count index length took: 8.58306884765625e-06 seconds\u001B[0m\n",
       "\u001B[0;31mfiltered mean took: 0.023256778717041016 seconds\u001B[0m\n",
       "\u001B[0;31mfiltered standard deviation took: 0.08786439895629883 seconds\u001B[0m\n",
       "\u001B[0;31mfiltered mean of columns addition took: 0.07608819007873535 seconds\u001B[0m\n",
       "\u001B[0;31mfiltered addition of columns took: 0.0799112319946289 seconds\u001B[0m\n",
       "\u001B[0;31mfiltered mean of columns multiplication took: 0.0737154483795166 seconds\u001B[0m\n",
       "\u001B[0;31mfiltered multiplication of columns took: 0.060573577880859375 seconds\u001B[0m\n",
       "\u001B[0;31mfiltered value counts took: 0.21976709365844727 seconds\u001B[0m\n",
       "\u001B[0;31mfiltered groupby statistics took: 0.4375126361846924 seconds\u001B[0m\n",
       "\u001B[0;31mfiltered join count took: 2.567830801010132 seconds\u001B[0m\n",
       "\u001B[0;31mfiltered join took: 1.4966778755187988 seconds\u001B[0m\n",
       "\u001B[0;31mcount took: 3.981590270996094e-05 seconds\u001B[0m\n",
       "\u001B[0;31mcount index length took: 6.67572021484375e-06 seconds\u001B[0m\n",
       "\u001B[0;31mmean took: 0.021521329879760742 seconds\u001B[0m\n",
       "\u001B[0;31mstandard deviation took: 0.13660049438476562 seconds\u001B[0m\n",
       "\u001B[0;31mmean of columns addition took: 0.12842440605163574 seconds\u001B[0m\n",
       "\u001B[0;31maddition of columns took: 0.1018679141998291 seconds\u001B[0m\n",
       "\u001B[0;31mmean of columns multiplication took: 0.13002276420593262 seconds\u001B[0m\n",
       "\u001B[0;31mmultiplication of columns took: 0.11522603034973145 seconds\u001B[0m\n",
       "\u001B[0;31mvalue counts took: 0.41176366806030273 seconds\u001B[0m\n",
       "\u001B[0;31mgroupby statistics took: 0.7312114238739014 seconds\u001B[0m"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mThe Python process exited with exit code 137 (SIGKILL: Killed). This may have been caused by an OOM error. Check your command's memory usage.\u001B[0m\n\u001B[0;31m\u001B[0m\n\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mThe last 10 KB of the process's stderr and stdout can be found below. See driver logs for full logs.\u001B[0m\n\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mLast messages on stderr:\u001B[0m\n\u001B[0;31mSun Jun  2 17:05:58 2024 Connection to spark from PID  5662\u001B[0m\n\u001B[0;31mSun Jun  2 17:05:58 2024 Initialized gateway on port 39861\u001B[0m\n\u001B[0;31mSun Jun  2 17:05:58 2024 Connected to spark.\u001B[0m\n\u001B[0;31m<command-1433832980640705>:53: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\u001B[0m\n\u001B[0;31m  result = df.groupby(\"passenger_count\").agg([\u001B[0m\n\u001B[0;31m<command-1433832980640705>:30: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\u001B[0m\n\u001B[0;31m  return df.groupby(\"fare_amount\").agg(pl.col(\"fare_amount\").count().alias(\"counts\")).sort(\"counts\")\u001B[0m\n\u001B[0;31m<command-1433832980640705>:53: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\u001B[0m\n\u001B[0;31m  result = df.groupby(\"passenger_count\").agg([\u001B[0m\n\u001B[0;31m<command-1433832980640705>:30: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\u001B[0m\n\u001B[0;31m  return df.groupby(\"fare_amount\").agg(pl.col(\"fare_amount\").count().alias(\"counts\")).sort(\"counts\")\u001B[0m\n\u001B[0;31m<command-1433832980640705>:53: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\u001B[0m\n\u001B[0;31m  result = df.groupby(\"passenger_count\").agg([\u001B[0m\n\u001B[0;31m<command-1433832980640705>:30: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\u001B[0m\n\u001B[0;31m  return df.groupby(\"fare_amount\").agg(pl.col(\"fare_amount\").count().alias(\"counts\")).sort(\"counts\")\u001B[0m\n\u001B[0;31m<command-1433832980640705>:53: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\u001B[0m\n\u001B[0;31m  result = df.groupby(\"passenger_count\").agg([\u001B[0m\n\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mLast messages on stdout:\u001B[0m\n\u001B[0;31mNOTE: When using the `ipython kernel` entry point, Ctrl-C will not work.\u001B[0m\n\u001B[0;31m\u001B[0m\n\u001B[0;31mTo exit, you will have to explicitly quit this process, by either sending\u001B[0m\n\u001B[0;31m\"quit\" from a client, or using Ctrl-\\ in UNIX-like environments.\u001B[0m\n\u001B[0;31m\u001B[0m\n\u001B[0;31mTo read more about this, see https://github.com/ipython/ipython/issues/2049\u001B[0m\n\u001B[0;31m\u001B[0m\n\u001B[0;31m\u001B[0m\n\u001B[0;31mTo connect another client to this kernel, use:\u001B[0m\n\u001B[0;31m    --existing /databricks/kernel-connections/94a690f7212ef9de48f914f409adb646fee4bec6693c856d278c40e6a4c27512.json\u001B[0m\n\u001B[0;31mpandas version: 1.4.2\u001B[0m\n\u001B[0;31mnumpy version: 1.21.5\u001B[0m\n\u001B[0;31mpolars version: 0.20.31\u001B[0m\n\u001B[0;31mpyarrow version: 7.0.0\u001B[0m\n\u001B[0;31mpyspark version: 3.3.2.dev0\u001B[0m\n\u001B[0;31mcount took: 0.0005140304565429688 seconds\u001B[0m\n\u001B[0;31mcount index length took: 1.1682510375976562e-05 seconds\u001B[0m\n\u001B[0;31mmean took: 0.03813910484313965 seconds\u001B[0m\n\u001B[0;31mstandard deviation took: 0.26393985748291016 seconds\u001B[0m\n\u001B[0;31mmean of columns addition took: 0.1642138957977295 seconds\u001B[0m\n\u001B[0;31maddition of columns took: 0.13327717781066895 seconds\u001B[0m\n\u001B[0;31mmean of columns multiplication took: 0.1623995304107666 seconds\u001B[0m\n\u001B[0;31mmultiplication of columns took: 0.13460636138916016 seconds\u001B[0m\n\u001B[0;31mvalue counts took: 0.5112097263336182 seconds\u001B[0m\n\u001B[0;31mgroupby statistics took: 0.7490234375 seconds\u001B[0m\n\u001B[0;31mjoin count took: 16.132195234298706 seconds\u001B[0m\n\u001B[0;31mjoin took: 5.184712171554565 seconds\u001B[0m\n\u001B[0;31mfiltered count took: 1.52587890625e-05 seconds\u001B[0m\n\u001B[0;31mfiltered count index length took: 8.58306884765625e-06 seconds\u001B[0m\n\u001B[0;31mfiltered mean took: 0.023256778717041016 seconds\u001B[0m\n\u001B[0;31mfiltered standard deviation took: 0.08786439895629883 seconds\u001B[0m\n\u001B[0;31mfiltered mean of columns addition took: 0.07608819007873535 seconds\u001B[0m\n\u001B[0;31mfiltered addition of columns took: 0.0799112319946289 seconds\u001B[0m\n\u001B[0;31mfiltered mean of columns multiplication took: 0.0737154483795166 seconds\u001B[0m\n\u001B[0;31mfiltered multiplication of columns took: 0.060573577880859375 seconds\u001B[0m\n\u001B[0;31mfiltered value counts took: 0.21976709365844727 seconds\u001B[0m\n\u001B[0;31mfiltered groupby statistics took: 0.4375126361846924 seconds\u001B[0m\n\u001B[0;31mfiltered join count took: 2.567830801010132 seconds\u001B[0m\n\u001B[0;31mfiltered join took: 1.4966778755187988 seconds\u001B[0m\n\u001B[0;31mcount took: 3.981590270996094e-05 seconds\u001B[0m\n\u001B[0;31mcount index length took: 6.67572021484375e-06 seconds\u001B[0m\n\u001B[0;31mmean took: 0.021521329879760742 seconds\u001B[0m\n\u001B[0;31mstandard deviation took: 0.13660049438476562 seconds\u001B[0m\n\u001B[0;31mmean of columns addition took: 0.12842440605163574 seconds\u001B[0m\n\u001B[0;31maddition of columns took: 0.1018679141998291 seconds\u001B[0m\n\u001B[0;31mmean of columns multiplication took: 0.13002276420593262 seconds\u001B[0m\n\u001B[0;31mmultiplication of columns took: 0.11522603034973145 seconds\u001B[0m\n\u001B[0;31mvalue counts took: 0.41176366806030273 seconds\u001B[0m\n\u001B[0;31mgroupby statistics took: 0.7312114238739014 seconds\u001B[0m",
       "errorSummary": "<span class='ansi-red-fg'>Fatal error</span>: The Python kernel is unresponsive.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#benchmark(read_file_parquet, df=None, benchmarks=dask_benchmarks, name='read file')\n",
    "benchmark(count, df=polars_data, benchmarks=polars_benchmarks, name='count')\n",
    "benchmark(count_index_length, df=polars_data, benchmarks=polars_benchmarks, name='count index length')\n",
    "benchmark(mean, df=polars_data, benchmarks=polars_benchmarks, name='mean')\n",
    "benchmark(standard_deviation, df=polars_data, benchmarks=polars_benchmarks, name='standard deviation')\n",
    "benchmark(mean_of_sum, df=polars_data, benchmarks=polars_benchmarks, name='mean of columns addition')\n",
    "benchmark(sum_columns, df=polars_data, benchmarks=polars_benchmarks, name='addition of columns')\n",
    "benchmark(mean_of_product, df=polars_data, benchmarks=polars_benchmarks, name='mean of columns multiplication')\n",
    "benchmark(product_columns, df=polars_data, benchmarks=polars_benchmarks, name='multiplication of columns')\n",
    "benchmark(value_counts, df=polars_data, benchmarks=polars_benchmarks, name='value counts')\n",
    "# No column for this\n",
    "# benchmark(mean_of_complicated_arithmetic_operation, df=dask_data, benchmarks=dask_benchmarks, name='mean of complex arithmetic ops')\n",
    "# benchmark(complicated_arithmetic_operation, df=dask_data, benchmarks=dask_benchmarks, name='complex arithmetic ops')\n",
    "benchmark(groupby_statistics, df=polars_data, benchmarks=polars_benchmarks, name='groupby statistics')\n",
    "benchmark(join_count, polars_data, benchmarks=polars_benchmarks, name='join count', other=other)\n",
    "benchmark(join_data, polars_data, benchmarks=polars_benchmarks, name='join', other=other) # cant join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5a41815-a460-4436-9003-88cf1dd54949",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Operations with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb148a69-1641-4d14-b180-781f07b60833",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "expr_filter = (polars_data[\"tip_amount\"] >= 1) & (polars_data[\"tip_amount\"] <= 5)\n",
    "\n",
    "def filter_data(df):\n",
    "    return df.filter(expr_filter)\n",
    "  \n",
    "polars_filtered = filter_data(polars_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efd5c38f-958f-4183-8113-61e2bf7f300b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered count took: 1.52587890625e-05 seconds\nfiltered count index length took: 8.58306884765625e-06 seconds\nfiltered mean took: 0.023256778717041016 seconds\nfiltered standard deviation took: 0.08786439895629883 seconds\nfiltered mean of columns addition took: 0.07608819007873535 seconds\nfiltered addition of columns took: 0.0799112319946289 seconds\nfiltered mean of columns multiplication took: 0.0737154483795166 seconds\nfiltered multiplication of columns took: 0.060573577880859375 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<command-1433832980640705>:30: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n  return df.groupby(\"fare_amount\").agg(pl.col(\"fare_amount\").count().alias(\"counts\")).sort(\"counts\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered value counts took: 0.21976709365844727 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<command-1433832980640705>:53: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n  result = df.groupby(\"passenger_count\").agg([\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered groupby statistics took: 0.4375126361846924 seconds\nfiltered join count took: 2.567830801010132 seconds\nfiltered join took: 1.4966778755187988 seconds\nOut[8]: 1.4966778755187988"
     ]
    }
   ],
   "source": [
    "benchmark(count, polars_filtered, benchmarks=polars_benchmarks, name='filtered count')\n",
    "benchmark(count_index_length, polars_filtered, benchmarks=polars_benchmarks, name='filtered count index length')\n",
    "benchmark(mean, polars_filtered, benchmarks=polars_benchmarks, name='filtered mean')\n",
    "benchmark(standard_deviation, polars_filtered, benchmarks=polars_benchmarks, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, polars_filtered, benchmarks=polars_benchmarks, name ='filtered mean of columns addition')\n",
    "benchmark(sum_columns, df=polars_filtered, benchmarks=polars_benchmarks, name='filtered addition of columns')\n",
    "benchmark(mean_of_product, polars_filtered, benchmarks=polars_benchmarks, name ='filtered mean of columns multiplication')\n",
    "benchmark(product_columns, df=polars_filtered, benchmarks=polars_benchmarks, name='filtered multiplication of columns')\n",
    "#benchmark(mean_of_complicated_arithmetic_operation, dask_filtered, benchmarks=dask_benchmarks, name='filtered mean of complex arithmetic ops')\n",
    "#benchmark(complicated_arithmetic_operation, dask_filtered, benchmarks=dask_benchmarks, name='filtered complex arithmetic ops')\n",
    "benchmark(value_counts, polars_filtered, benchmarks=polars_benchmarks, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, polars_filtered, benchmarks=polars_benchmarks, name='filtered groupby statistics')\n",
    "\n",
    "# other = groupby_statistics(polars_filtered)\n",
    "# other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "other = groupby_statistics(polars_data)\n",
    "\n",
    "benchmark(join_count, polars_filtered, benchmarks=polars_benchmarks, name='filtered join count', other=other)\n",
    "benchmark(join_data, polars_filtered, benchmarks=polars_benchmarks, name='filtered join', other=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "714dad1d-fa8c-4d80-8e9e-55af7ed7c83a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.000514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count index length</th>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.038139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standard deviation</th>\n",
       "      <td>0.263940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean of columns addition</th>\n",
       "      <td>0.164214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addition of columns</th>\n",
       "      <td>0.133277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean of columns multiplication</th>\n",
       "      <td>0.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiplication of columns</th>\n",
       "      <td>0.134606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value counts</th>\n",
       "      <td>0.511210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groupby statistics</th>\n",
       "      <td>0.749023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>join count</th>\n",
       "      <td>16.132195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>join</th>\n",
       "      <td>5.184712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered count</th>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered count index length</th>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered mean</th>\n",
       "      <td>0.023257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered standard deviation</th>\n",
       "      <td>0.087864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered mean of columns addition</th>\n",
       "      <td>0.076088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered addition of columns</th>\n",
       "      <td>0.079911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered mean of columns multiplication</th>\n",
       "      <td>0.073715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered multiplication of columns</th>\n",
       "      <td>0.060574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered value counts</th>\n",
       "      <td>0.219767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered groupby statistics</th>\n",
       "      <td>0.437513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered join count</th>\n",
       "      <td>2.567831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered join</th>\n",
       "      <td>1.496678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n    </tr>\n    <tr>\n      <th>task</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>0.000514</td>\n    </tr>\n    <tr>\n      <th>count index length</th>\n      <td>0.000012</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.038139</td>\n    </tr>\n    <tr>\n      <th>standard deviation</th>\n      <td>0.263940</td>\n    </tr>\n    <tr>\n      <th>mean of columns addition</th>\n      <td>0.164214</td>\n    </tr>\n    <tr>\n      <th>addition of columns</th>\n      <td>0.133277</td>\n    </tr>\n    <tr>\n      <th>mean of columns multiplication</th>\n      <td>0.162400</td>\n    </tr>\n    <tr>\n      <th>multiplication of columns</th>\n      <td>0.134606</td>\n    </tr>\n    <tr>\n      <th>value counts</th>\n      <td>0.511210</td>\n    </tr>\n    <tr>\n      <th>groupby statistics</th>\n      <td>0.749023</td>\n    </tr>\n    <tr>\n      <th>join count</th>\n      <td>16.132195</td>\n    </tr>\n    <tr>\n      <th>join</th>\n      <td>5.184712</td>\n    </tr>\n    <tr>\n      <th>filtered count</th>\n      <td>0.000015</td>\n    </tr>\n    <tr>\n      <th>filtered count index length</th>\n      <td>0.000009</td>\n    </tr>\n    <tr>\n      <th>filtered mean</th>\n      <td>0.023257</td>\n    </tr>\n    <tr>\n      <th>filtered standard deviation</th>\n      <td>0.087864</td>\n    </tr>\n    <tr>\n      <th>filtered mean of columns addition</th>\n      <td>0.076088</td>\n    </tr>\n    <tr>\n      <th>filtered addition of columns</th>\n      <td>0.079911</td>\n    </tr>\n    <tr>\n      <th>filtered mean of columns multiplication</th>\n      <td>0.073715</td>\n    </tr>\n    <tr>\n      <th>filtered multiplication of columns</th>\n      <td>0.060574</td>\n    </tr>\n    <tr>\n      <th>filtered value counts</th>\n      <td>0.219767</td>\n    </tr>\n    <tr>\n      <th>filtered groupby statistics</th>\n      <td>0.437513</td>\n    </tr>\n    <tr>\n      <th>filtered join count</th>\n      <td>2.567831</td>\n    </tr>\n    <tr>\n      <th>filtered join</th>\n      <td>1.496678</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "polars_res_temp = get_results(polars_benchmarks).set_index('task')\n",
    "polars_res_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57a4c294-909a-4fa1-a8ae-ec0b8543a80d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "polars",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
